job_id,job_title,company_name,descprition
4146066012,Staff Data Engineer - Data Science,LinkedIn,"LinkedIn is the world’s largest professional network, built to help members of all backgrounds and experiences achieve more in their careers. Our vision is to create economic opportunity for every member of the global workforce. Every day our members use our products to make connections, discover opportunities, build skills and gain insights. We believe amazing things happen when we work together in an environment where everyone feels a true sense of belonging, and that what matters most in a candidate is having the skills needed to succeed. It inspires us to invest in our talent and support career growth. Join us to challenge yourself with work that matters. At LinkedIn, we trust each other to do our best work where it works best for us and our teams. This role offers a hybrid work option, meaning you can both work from home and commute to a LinkedIn office, depending on what’s best for you and when it is important for your team to be together. LinkedIn’s Data Science team leverages big data to empower business decisions and deliver data-driven insights, metrics, and tools in order to drive member engagement, business growth, and monetization efforts. With over 1 billion members around the world, a focus on great user experience, and a mix of B2B and B2C programs, LinkedIn offers countless ways for an ambitious data engineer to have an impact and transform your career. We are now looking for a talented and driven individual to accelerate our efforts and be a major part of our data-centric culture. This person will work closely with various cross-functional teams such as product, marketing, sales, engineering, and operations to develop infrastructure and deliver tools or data structures that enable data-driven decision-making. Successful candidates will exhibit technical acumen and business savviness with a passion for making an impact by enabling both producers and consumers of data insight to work smarter. Responsibilities: • Work with a team of high-performing data science professionals, and cross-functional teams to identify business opportunities and build scalable data solutions. Build data expertise, act like an owner for the company and manage complex data systems for a product or a group of products. • Perform all of the necessary data transformations to serve products that empower data-driven decision making. • Establish efficient design and programming patterns for engineers as well as for non-technical partners. • Design, implement, integrate and document performant systems or components for data flows or applications that power analysis at a massive scale. • Ensure best practices and standards in our data ecosystem are shared across teams. • Understand the analytical objectives to make logical recommendations and drive informed actions. • Engage with internal data platform teams to prototype and validate tools developed in-house to derive insight from very large datasets or automate complex algorithms. • Contribute to engineering innovations that fuel LinkedIn’s vision and mission. Basic Qualifications: • Bachelor's Degree in a quantitative discipline: Computer Science, Statistics, Operations Research, Informatics, Engineering, Applied Mathematics, Economics, etc • 4+ years of relevant industry or relevant academia experience working with large amounts of data • Experience with SQL/Relational databases • Background in at least one programming languages (e.g., R, Python, Java, Scala, PHP, JavaScript) Preferred Qualifications: • BS and 7+ years of relevant work experience, MS and 5+ years of relevant work experience, or Ph.D. and 3+ years of relevant work/academia experience working with large amounts of data • MS or PhD in a quantitative discipline: Statistics, Operations Research, Computer Science, Informatics, Engineering, Applied Mathematics, Economics, etc. Suggested Skills : • Java • Distributed Systems • Relational Databases • Technical Leadership You will Benefit from our Culture: We strongly believe in the well-being of our employees and their families. That is why we offer generous health and wellness programs and time away for employees of all levels. LinkedIn is committed to fair and equitable compensation practices. The pay range for this role is $147,000.00 to $240,000.00 Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to skill set, depth of experience, certifications, and specific work location. This may be different in other locations due to differences in the cost of labor. The total compensation package for this position may also include annual performance bonus, stock, benefits and/or other applicable incentive compensation plans. For more information, visit https://careers.linkedin.com/benefits. Equal Opportunity Statement LinkedIn is committed to diversity in its workforce and is proud to be an equal opportunity employer. LinkedIn considers qualified applicants without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, marital status, pregnancy, sex, gender expression or identity, sexual orientation, citizenship, or any other legally protected class. LinkedIn is an Affirmative Action and Equal Opportunity Employer as described in our equal opportunity statement here: https://microsoft.sharepoint.com/:b:/t/LinkedInGCI/EeE8sk7CTIdFmEp9ONzFOTEBM62TPrWLMHs4J1C_QxVTbg?e=5hfhpE. Please reference https://www.eeoc.gov/sites/default/files/2023-06/22-088_EEOC_KnowYourRights6.12ScreenRdr.pdf and https://www.dol.gov/ofccp/regs/compliance/posters/pdf/OFCCP_EEO_Supplement_Final_JRF_QA_508c.pdf for more information. LinkedIn is committed to offering an inclusive and accessible experience for all job seekers, including individuals with disabilities. Our goal is to foster an inclusive and accessible workplace where everyone has the opportunity to be successful. If you need a reasonable accommodation to search for a job opening, apply for a position, or participate in the interview process, connect with us at accommodations@linkedin.com and describe the specific accommodation requested for a disability-related limitation. Reasonable accommodations are modifications or adjustments to the application or hiring process that would enable you to fully participate in that process. Examples of reasonable accommodations include but are not limited to: -Documents in alternate formats or read aloud to you -Having interviews in an accessible location -Being accompanied by a service dog -Having a sign language interpreter present for the interview A request for an accommodation will be responded to within three business days. However, non-disability related requests, such as following up on an application, will not receive a response. LinkedIn will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by LinkedIn, or (c) consistent with LinkedIn's legal duty to furnish information. Pay Transparency Policy Statement As a federal contractor, LinkedIn follows the Pay Transparency and non-discrimination provisions described at this link: https://lnkd.in/paytransparency. Global Data Privacy Notice for Job Candidates This document provides transparency around the way in which LinkedIn handles personal data of employees and job applicants: https://lnkd.in/GlobalDataPrivacyNotice"
4124801858,Data Engineer,Adobe,"Our Company Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen. We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours! Be a part of Adobe’s Experience Platform; our fastest growing business in the Experience Cloud! The Adobe Experience Platform manages petabytes of data on behalf of organizations allowing them to have a centralized and standardized data platform applying data science and machine learning to improve the design and delivery of rich, personalized experiences. Adobe Experience Platform is seeking a Software Development Engineer to join the operational intelligence team. We build scalable, performant services and tools to handle end to end customer lifecycle from provisioning everything needed for onboarding customers when they purchase AEP to analyzing customer usage data and behaviors to generate business critical insights. We are looking for innovative and passionate software engineers to build low latency & highly scalable fault tolerant systems. What you will do: Design and develop distributed services that are resilient, highly available and scalable. Collaborate with business partners, architects, technical leads, product management and analysts to develop high-quality customer centric solutions. Participate in all aspects of software development activities, including design, coding, code review, unit and integration testing, bug fixing, deploy and code/API documentation. Own feature development from inception to production rollout and postmortem & contribute to the development of engineering processes. Help evaluate innovative technologies and incorporate them into our stack. What you will need to succeed: B.S. or M.S. in Computer Science or equivalent engineering degree. 3+ years of software engineering experience having built highly maintainable, scalable systems with Scala/Java or comparable strongly typed language. Experience with data transformation & ELT pipelines on large data sets using Databricks, SnowFlake, SQL, Python, Jupyter Notebooks. Excellent data analysis, problem-solving skills & proficiency with data visualization tools (e.g. Power BI, Tableau, Looker) Experience with building & deploying machine learning models & ML pipelines such as Sklearn, Tensorflow, PyTorch, KubeFlow, MLFlow, SageMaker, or similar. Ability to multi-task simultaneously different projects, having a positive outlook, motivated learner with strong interpersonal and written and verbal communication skills. What will help you stand out from the crowd Unending curiosity, thoroughness, tenacity and focus on designing and building complex software systems with excellent quality to address customer problems. Experience developing backend distributed applications on Java/JVM and Spring (or similar framework). Shown experience using structured, focused approaches to solving technical, data, and logical problems. Our compensation reflects the cost of labor across several U.S. geographic markets, and we pay differently based on those defined markets. The U.S. pay range for this position is $113,400 -- $206,300 annually. Pay within this range varies by work location and may also depend on job-related knowledge, skills, and experience. Your recruiter can share more about the specific salary range for the job location during the hiring process. At Adobe, for sales roles starting salaries are expressed as total target compensation (TTC = base + commission), and short-term incentives are in the form of sales commission plans. Non-sales roles starting salaries are expressed as base salary and short-term incentives are in the form of the Annual Incentive Plan (AIP). In addition, certain roles may be eligible for long-term incentives in the form of a new hire equity award. Adobe will consider qualified applicants with arrest or conviction records for employment in accordance with state and local laws and “fair chance” ordinances. Adobe is proud to be an Equal Employment Opportunity and affirmative action employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more. Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015. Adobe values a free and open marketplace for all employees and has policies in place to ensure that we do not enter into illegal agreements with other companies to not recruit or hire each other’s employees."
4169661048,Data Engineer,Lattice,"This is Data Science at Lattice As a Data Engineer on our Data Science team, you will play a pivotal role in designing, building, and optimizing our data infrastructure to support data-driven decision-making across the organization. You will collaborate closely with data scientists, analysts, and other stakeholders to deliver high-quality data solutions that meet business needs. Your responsibilities will include writing production-level data transformations, managing ETL processes, and ensuring the performance and reliability of our data warehouse. With your expertise in SQL, Python, and data orchestration tools like Airflow, you will drive best practices and contribute to the velocity of our team and the continuous improvement of our tech stack. What You Will Do Write production-level data transformations to support stakeholders across data and business intelligence applications Create documentation and testing to ensure that our data is accurate and easily understandable Maintain and optimize performance of our data warehouse by designing efficient tables and storage processes Share methodologies and instruct other data team members on how to best write data transformations Collaborate with cross-functional teams to support data-driven initiatives and projects. Discover and institute best practices to ensure data quality across all facets of the data team Research and implement new tooling to enhance our tech stack Manage our ETL and other orchestrated processes through third party tools and first-party tools such as Airflow Enforce code quality by identifying and reducing tech debt, standardizing styles, and removing deprecated objects from code and downstream locations Work closely with data scientists, analysts, and other stakeholders to understand data requirements and deliver solutions What You Will Bring To The Table Fluency in SQL and dbt Proficiency in Python Experience with git and cloud platforms (e.g. AWS) Knowledge of data orchestration tools like Airflow, Prefect, or Dagster Excellent communication and collaboration skills High attention to detail and ability to think structurally about a solution Experience with a BI Tool (preferably Looker) A strong commitment to Lattice’s mission and values, including Ship Shipmate Self, Clear Eyes, Own The Outcome, and What’s Next? The estimated annual cash salary for this role is $123,000 - $154,000. This position is also eligible for incentive stock options, subject to the terms of Lattice’s applicable plans. Benefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: Medical insurance; Dental insurance; Vision insurance; Life, AD&D, and Disability Insurance; Emergency Weather Support; Wellness Apps; Paid Parental Leave, Paid Time off inclusive of holidays and sick time; Commuter & Parking Accounts; Lunches in the Office; Internet and Phone Stipend; One time WFH Office Set-Up Stipend; 401(k) retirement plan; Financial Planning; Learning & Development Budget; Sabbatical Program; and Invest in Your People Fund Note on Pay Transparency: Lattice provides an estimate of the compensation for roles that may be hired as required by state regulations. Compensation may vary based on (a) location, as Lattice factors in specific location when benchmarking compensation for most roles; (b) individual candidate skills and qualifications; and (c) individual candidate experience. Additionally, Lattice leverages current market data to determine compensation, so posted compensation figures are subject to change as new market data becomes available. The salary, other compensation, and benefits information is accurate as of the date of this posting. Lattice reserves the right to modify this information at any time, subject to applicable law. About Lattice Lattice is on a mission to build cultures where employees and their companies thrive. In an age where employees have more choices than ever before, businesses that put employees first are winning 🏅– and Lattice is building the tools to empower those people-centric companies. Lattice is a people success platform that offers performance reviews, employee engagement surveys, real-time feedback, weekly check-ins, goal setting, and career planning in a way that allows companies to focus on employee development, growth, and engagement – yielding stronger employee retention, performance, and impact to the bottom line 📈. Since launching in 2016, we have grown to over 5,000+ customers globally, including brands like Loom, Robinhood, and Gusto. Lattice is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to gender, race, religion, national origin, ethnicity, disability, gender identity/expression, sexual orientation, veteran or military status, or any other category protected under the law. Lattice is an equal opportunity employer; committed to a community of inclusion, and an environment free from discrimination, harassment, and retaliation. By clicking the ""Submit Application"" button below, you consent to Lattice processing your personal information for the purpose of assessing your candidacy for this position in accordance with Lattice's Job Applicant Privacy Policy ."
4115022421,Data Engineer,Atlassian,"Overview Atlassian is looking for a Data Engineer to join our Data Engineering team and build world-class data solutions and applications that power crucial decisions throughout the organisation. We are looking for an open-minded, structured thinker who is passionate about building systems at scale. You will enable a world-class data engineering practice, drive the approach with which we use data, develop backend systems and data models to serve the needs of insights and play an active role in building Atlassian’s data-driven culture. Working at Atlassian Atlassians can choose where they work – whether in an office, from home, or a combination of the two. That way, Atlassians have more control over supporting their family, personal goals, and other priorities. We can hire people in any country where we have a legal entity. Interviews and onboarding are conducted virtually, a part of being a distributed-first company. Responsibilities Data is a BIG deal at Atlassian. We ingest over 180 billion events each month into our analytics platform and we have dozens of teams across the company driving their decisions and guiding their operations based on the data and services we provide. The data engineering team manages several data models and data pipelines across Atlassian, including finance, growth, product analysis, customer support, sales, and marketing. You'll join a team that is smart and very direct. We ask hard questions and challenge each other to constantly improve our work. As a Data Engineer, you will apply your technical expertise to build analytical data models that support a broad range of analytical requirements across the company. You will work with extended teams to evolve solutions as business processes and requirements change. You'll own problems end-to-end and on an ongoing basis, you'll improve the data by adding new sources, coding business rules, and producing new metrics that support the business. Qualifications Bachelor’s/Master's degree or equivalent in a STEM field with a minimum 2+ Years of Experience in Data Engineering or related field. Expertise in Python or other modern programming languages. Working knowledge of relational databases and query authoring via SQL. Experience designing data models for optimal storage, retrieval and dashboarding to meet product and business requirements. Experience building scalable data pipelines using Spark or Spark-SQL with Airflow scheduler/executor framework or similar scheduling tools. Experience building real-time data pipelines using a micro-services architecture. Experience working with AWS data services or similar Apache projects (Spark, Flink, Hive, and Kafka). Understanding of Data Engineering tools/frameworks and standards to improve the productivity and quality of output for Data Engineers across the team. Well-versed in modern software development practices (Agile, TDD, CICD). Compensation At Atlassian, we strive to design equitable, explainable, and competitive compensation programs. To support this goal, the baseline of our range is higher than that of the typical market range, but in turn we expect to hire most candidates near this baseline. Base pay within the range is ultimately determined by a candidate's skills, expertise, or experience. In the United States, we have three geographic pay zones. For this role, our current base pay ranges for new hires in each zone are: Zone A: $140,100 - $186,800 Zone B: $126,100 - $168,200 Zone C: $116,300 - $155,100 This role may also be eligible for benefits, bonuses, commissions, and equity. Please visit go.atlassian.com/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter. Our Perks & Benefits Atlassian offers a variety of perks and benefits to support you, your family and to help you engage with your local community. Our offerings include health coverage, paid volunteer days, wellness resources, and so much more. Visit go.atlassian.com/perksandbenefits to learn more. About Atlassian At Atlassian, we're motivated by a common goal: to unleash the potential of every team. Our software products help teams all over the planet and our solutions are designed for all types of work. Team collaboration through our tools makes what may be impossible alone, possible together. We believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines. To provide you the best experience, we can support with accommodations or adjustments at any stage of the recruitment process. Simply inform our Recruitment team during your conversation with them. To learn more about our culture and hiring process, visit go.atlassian.com/crh ."
4144480276,Data Engineer Jr.,CGI,"Position Description CGI is seeking a motivated individual who is passionate about helping the team and clients achieve excellence. Qualified candidates will have a creative, holistic, and systematic approach to problem-solving. The Data Engineer is responsible for assisting our client with building a robust data infrastructure to extract insights that enable data driven decision making. The successful candidate will have a broad understanding of computer and information science principles to build data pipelines using SQL, Python and PySpark. They will import and sync to various data sources, clean and standardize data elements, and fix data quality issues. They will collect, manage, and convert raw data into a usable format for the data scientists This position is located in our Arlington, VA office; however, a hybrid working model is acceptable for candidates within the National Capital Region. Due to the nature of work a Secret Security Clearance is required. Your future duties and responsibilities Creating and maintaining scalable data pipelines from multiple sources Collecting and storing data from multiple sources Building, maintaining, and optimizing data tables Coordinating with data scientists to ensure data infrastructure needs are met Communicating with leadership to articulate progress of ongoing data initiatives as well as any blockers. Building and maintaining processes to monitor and ensure data quality ensuring accurate information is fed into executive level dashboards Required qualifications to be successful in this role: Required Qualifications To Be Successful In This Role Bachelor's Degree in similar field. 2-3 years of experience in data integration and management Experience with SQL, Python and PySpark Excellent analytical and problem-solving skill Excellent oral and written communication skills Desired qualifications/non-essential skills required: Experience with Databricks or Data Lakes desired CGI is required by law in some jurisdictions to include a reasonable estimate of the compensation range for this role. The determination of this range includes various factors not limited to skill set, level, experience, relevant training, and licensure and certifications. To support the ability to reward for merit-based performance, CGI typically does not hire individuals at or near the top of the range for their role. Compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range for this role in the U.S. is $85,000.00 - $121,900.00. CGI Federal's benefits are offered to eligible professionals on their first day of employment to include: Competitive compensation Comprehensive insurance options Matching contributions through the 401(k) plan and the share purchase plan Paid time off for vacation, holidays, and sick time Paid parental leave Learning opportunities and tuition assistance Wellness and Well-being programs #CGIFederalJob Together, as owners, let’s turn meaningful insights into action. Life at CGI is rooted in ownership, teamwork, respect and belonging. Here, you’ll reach your full potential because… You are invited to be an owner from day 1 as we work together to bring our Dream to life. That’s why we call ourselves CGI Partners rather than employees. We benefit from our collective success and actively shape our company’s strategy and direction. Your work creates value. You’ll develop innovative solutions and build relationships with teammates and clients while accessing global capabilities to scale your ideas, embrace new opportunities, and benefit from expansive industry and technology expertise. You’ll shape your career by joining a company built to grow and last. You’ll be supported by leaders who care about your health and well-being and provide you with opportunities to deepen your skills and broaden your horizons. Come join our team—one of the largest IT and business consulting services firms in the world. Qualified applicants will receive consideration for employment without regard to their race, ethnicity, ancestry, color, sex, religion, creed, age, national origin, citizenship status, disability, pregnancy, medical condition, military and veteran status, marital status, sexual orientation or perceived sexual orientation, gender, gender identity, and gender expression, familial status or responsibilities, reproductive health decisions, political affiliation, genetic information, height, weight, or any other legally protected status or characteristics. CGI provides reasonable accommodations to qualified individuals with disabilities. If you need an accommodation to apply for a job in the U.S., please email the CGI U.S. Employment Compliance mailbox at US_Employment_Compliance@cgi.com. You will need to reference the Position ID of the position in which you are interested. Your message will be routed to the appropriate recruiter who will assist you. Please note, this email address is only to be used for those individuals who need an accommodation to apply for a job. Emails for any other reason or those that do not include a Position ID will not be returned. We make it easy to translate military experience and skills! Click here to be directed to our site that is dedicated to veterans and transitioning service members. All CGI offers of employment in the U.S. are contingent upon the ability to successfully complete a background investigation. Background investigation components can vary dependent upon specific assignment and/or level of US government security clearance held. Dependent upon role and/or federal government security clearance requirements, and in accordance with applicable laws, some background investigations may include a credit check. CGI will consider for employment qualified applicants with arrests and conviction records in accordance with all local regulations and ordinances. CGI will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with CGI’s legal duty to furnish information."
4171303033,Data Engineer Intern,The Clorox Company,"Clorox is the place that’s committed to growth – for our people and our brands. Guided by our purpose and values, and with people at the center of everything we do, we believe every one of us can make a positive impact on consumers, communities, and teammates. Join our team. #CloroxIsThePlace Your role at Clorox: Join our dynamic team as a Data Engineer Intern! As a Data Engineer Intern at our organization, you will have the opportunity to work with cutting-edge technologies within the Azure stack. You’ll collaborate closely with the Finance Transformation Team, gain hands-on experience, and contribute to impactful data engineering projects. If you have a passion for data, analytics, and cloud technologies and are eager to develop your business data acumen, this role is perfect for you! In this role, you will: Key Responsibilities Quality Assurance (QA) Tasks: Assist in identifying and resolving QA bugs related to data pipelines and processes, ensuring data integrity and reliability. Validate data accuracy, completeness, and consistency by performing rigorous testing and analysis. Pipeline Engineering: Participate in designing, building, and maintaining data pipelines. Implement data transformations, data cleansing, and ETL processes to ensure high-quality data flow. Collaborate with senior engineers to enhance pipeline efficiency and performance. Small Feature Development: Take ownership of small features within the data pipeline. Write code to handle data ingestion, processing, and storage, ensuring seamless data integration. Independent Project: Lead a small independent project related to data engineering, choosing a topic of interest (e.g., optimizing pipeline performance, automating data validation). Present your findings and recommendations to the team. What we look for: Key Skills, Abilities, And Experience Required Education: Currently a Junior or Rising Senior in college pursuing a STEM degree (e.g., Computer Science, Engineering, Information Technology, etc.). Technical Skills: Proficiency in SQL, Python, and PySpark. Familiarity with Azure services such as Data Factory, Synapse, Databricks, and Azure Functions. Experience with data integration using APIs. Knowledge of data visualization tools (Power BI, Tableau). Analytical Skills: Strong problem-solving abilities with the capability to provide solutions and recommendations. Ability to document business requirements effectively in the form of Standard Operating Procedures (SOPs). Collaboration and Communication: Excellent teamwork and communication skills with cross-functional partners. Workplace type: We seek out and celebrate diverse backgrounds and experiences. We’re looking for fresh perspectives, a desire to bring your best, and a non-stop drive to keep growing and learning. At Clorox, we have a Culture of Inclusion. We believe our values-based culture connects to our purpose and helps our people be the best versions of themselves, professionally and personally. This means building a workplace where every person can feel respected, valued, and fully able to participate in our Clorox community. Learn more about our I&D program & initiatives here . Benefits we offer to help you be well and thrive: Competitive compensation Generous 401(k) program in the US and similar programs in international Health benefits and programs that support both your physical and mental well-being Flexible work environment, depending on your role Meaningful opportunities to keep learning and growing Half-day Fridays, depending on your location Please apply directly to our job postings and do not submit your resume to any person via text message. Clorox does not conduct text-based interviews and encourages you to be cautious of anyone posing as a Clorox recruiter via unsolicited texts during these uncertain times. To all recruitment agencies: Clorox (and its brand families) does not accept agency resumes. Please do not forward resumes to Clorox employees, including any members of our leadership team. Clorox is not responsible for any fees related to unsolicited resumes."
4115021577,Data Engineer,Atlassian,"Overview Atlassian is looking for a Data Engineer to join our Data Engineering team and build world-class data solutions and applications that power crucial decisions throughout the organisation. We are looking for an open-minded, structured thinker who is passionate about building systems at scale. You will enable a world-class data engineering practice, drive the approach with which we use data, develop backend systems and data models to serve the needs of insights and play an active role in building Atlassian’s data-driven culture. Working at Atlassian Atlassians can choose where they work – whether in an office, from home, or a combination of the two. That way, Atlassians have more control over supporting their family, personal goals, and other priorities. We can hire people in any country where we have a legal entity. Interviews and onboarding are conducted virtually, a part of being a distributed-first company. Responsibilities Data is a BIG deal at Atlassian. We ingest over 180 billion events each month into our analytics platform and we have dozens of teams across the company driving their decisions and guiding their operations based on the data and services we provide. The data engineering team manages several data models and data pipelines across Atlassian, including finance, growth, product analysis, customer support, sales, and marketing. You'll join a team that is smart and very direct. We ask hard questions and challenge each other to constantly improve our work. As a Data Engineer, you will apply your technical expertise to build analytical data models that support a broad range of analytical requirements across the company. You will work with extended teams to evolve solutions as business processes and requirements change. You'll own problems end-to-end and on an ongoing basis, you'll improve the data by adding new sources, coding business rules, and producing new metrics that support the business. Qualifications Bachelor’s/Master's degree or equivalent in a STEM field with a minimum 2+ Years of Experience in Data Engineering or related field. Expertise in Python or other modern programming languages. Working knowledge of relational databases and query authoring via SQL. Experience designing data models for optimal storage, retrieval and dashboarding to meet product and business requirements. Experience building scalable data pipelines using Spark or Spark-SQL with Airflow scheduler/executor framework or similar scheduling tools. Experience building real-time data pipelines using a micro-services architecture. Experience working with AWS data services or similar Apache projects (Spark, Flink, Hive, and Kafka). Understanding of Data Engineering tools/frameworks and standards to improve the productivity and quality of output for Data Engineers across the team. Well-versed in modern software development practices (Agile, TDD, CICD). Compensation At Atlassian, we strive to design equitable, explainable, and competitive compensation programs. To support this goal, the baseline of our range is higher than that of the typical market range, but in turn we expect to hire most candidates near this baseline. Base pay within the range is ultimately determined by a candidate's skills, expertise, or experience. In the United States, we have three geographic pay zones. For this role, our current base pay ranges for new hires in each zone are: Zone A: $140,100 - $186,800 Zone B: $126,100 - $168,200 Zone C: $116,300 - $155,100 This role may also be eligible for benefits, bonuses, commissions, and equity. Please visit go.atlassian.com/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter. Our Perks & Benefits Atlassian offers a variety of perks and benefits to support you, your family and to help you engage with your local community. Our offerings include health coverage, paid volunteer days, wellness resources, and so much more. Visit go.atlassian.com/perksandbenefits to learn more. About Atlassian At Atlassian, we're motivated by a common goal: to unleash the potential of every team. Our software products help teams all over the planet and our solutions are designed for all types of work. Team collaboration through our tools makes what may be impossible alone, possible together. We believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines. To provide you the best experience, we can support with accommodations or adjustments at any stage of the recruitment process. Simply inform our Recruitment team during your conversation with them. To learn more about our culture and hiring process, visit go.atlassian.com/crh ."
4115023391,Data Engineer,Atlassian,"Overview Atlassian is looking for a Data Engineer to join our Data Engineering team and build world-class data solutions and applications that power crucial decisions throughout the organisation. We are looking for an open-minded, structured thinker who is passionate about building systems at scale. You will enable a world-class data engineering practice, drive the approach with which we use data, develop backend systems and data models to serve the needs of insights and play an active role in building Atlassian’s data-driven culture. Working at Atlassian Atlassians can choose where they work – whether in an office, from home, or a combination of the two. That way, Atlassians have more control over supporting their family, personal goals, and other priorities. We can hire people in any country where we have a legal entity. Interviews and onboarding are conducted virtually, a part of being a distributed-first company. Responsibilities Data is a BIG deal at Atlassian. We ingest over 180 billion events each month into our analytics platform and we have dozens of teams across the company driving their decisions and guiding their operations based on the data and services we provide. The data engineering team manages several data models and data pipelines across Atlassian, including finance, growth, product analysis, customer support, sales, and marketing. You'll join a team that is smart and very direct. We ask hard questions and challenge each other to constantly improve our work. As a Data Engineer, you will apply your technical expertise to build analytical data models that support a broad range of analytical requirements across the company. You will work with extended teams to evolve solutions as business processes and requirements change. You'll own problems end-to-end and on an ongoing basis, you'll improve the data by adding new sources, coding business rules, and producing new metrics that support the business. Qualifications Bachelor’s/Master's degree or equivalent in a STEM field with a minimum 2+ Years of Experience in Data Engineering or related field. Expertise in Python or other modern programming languages. Working knowledge of relational databases and query authoring via SQL. Experience designing data models for optimal storage, retrieval and dashboarding to meet product and business requirements. Experience building scalable data pipelines using Spark or Spark-SQL with Airflow scheduler/executor framework or similar scheduling tools. Experience building real-time data pipelines using a micro-services architecture. Experience working with AWS data services or similar Apache projects (Spark, Flink, Hive, and Kafka). Understanding of Data Engineering tools/frameworks and standards to improve the productivity and quality of output for Data Engineers across the team. Well-versed in modern software development practices (Agile, TDD, CICD). Compensation At Atlassian, we strive to design equitable, explainable, and competitive compensation programs. To support this goal, the baseline of our range is higher than that of the typical market range, but in turn we expect to hire most candidates near this baseline. Base pay within the range is ultimately determined by a candidate's skills, expertise, or experience. In the United States, we have three geographic pay zones. For this role, our current base pay ranges for new hires in each zone are: Zone A: $140,100 - $186,800 Zone B: $126,100 - $168,200 Zone C: $116,300 - $155,100 This role may also be eligible for benefits, bonuses, commissions, and equity. Please visit go.atlassian.com/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter. Our Perks & Benefits Atlassian offers a variety of perks and benefits to support you, your family and to help you engage with your local community. Our offerings include health coverage, paid volunteer days, wellness resources, and so much more. Visit go.atlassian.com/perksandbenefits to learn more. About Atlassian At Atlassian, we're motivated by a common goal: to unleash the potential of every team. Our software products help teams all over the planet and our solutions are designed for all types of work. Team collaboration through our tools makes what may be impossible alone, possible together. We believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines. To provide you the best experience, we can support with accommodations or adjustments at any stage of the recruitment process. Simply inform our Recruitment team during your conversation with them. To learn more about our culture and hiring process, visit go.atlassian.com/crh ."
4115017957,Data Engineer,Atlassian,"Overview Atlassian is looking for a Data Engineer to join our Data Engineering team and build world-class data solutions and applications that power crucial decisions throughout the organisation. We are looking for an open-minded, structured thinker who is passionate about building systems at scale. You will enable a world-class data engineering practice, drive the approach with which we use data, develop backend systems and data models to serve the needs of insights and play an active role in building Atlassian’s data-driven culture. Working at Atlassian Atlassians can choose where they work – whether in an office, from home, or a combination of the two. That way, Atlassians have more control over supporting their family, personal goals, and other priorities. We can hire people in any country where we have a legal entity. Interviews and onboarding are conducted virtually, a part of being a distributed-first company. Responsibilities Data is a BIG deal at Atlassian. We ingest over 180 billion events each month into our analytics platform and we have dozens of teams across the company driving their decisions and guiding their operations based on the data and services we provide. The data engineering team manages several data models and data pipelines across Atlassian, including finance, growth, product analysis, customer support, sales, and marketing. You'll join a team that is smart and very direct. We ask hard questions and challenge each other to constantly improve our work. As a Data Engineer, you will apply your technical expertise to build analytical data models that support a broad range of analytical requirements across the company. You will work with extended teams to evolve solutions as business processes and requirements change. You'll own problems end-to-end and on an ongoing basis, you'll improve the data by adding new sources, coding business rules, and producing new metrics that support the business. Qualifications Bachelor’s/Master's degree or equivalent in a STEM field with a minimum 2+ Years of Experience in Data Engineering or related field. Expertise in Python or other modern programming languages. Working knowledge of relational databases and query authoring via SQL. Experience designing data models for optimal storage, retrieval and dashboarding to meet product and business requirements. Experience building scalable data pipelines using Spark or Spark-SQL with Airflow scheduler/executor framework or similar scheduling tools. Experience building real-time data pipelines using a micro-services architecture. Experience working with AWS data services or similar Apache projects (Spark, Flink, Hive, and Kafka). Understanding of Data Engineering tools/frameworks and standards to improve the productivity and quality of output for Data Engineers across the team. Well-versed in modern software development practices (Agile, TDD, CICD). Compensation At Atlassian, we strive to design equitable, explainable, and competitive compensation programs. To support this goal, the baseline of our range is higher than that of the typical market range, but in turn we expect to hire most candidates near this baseline. Base pay within the range is ultimately determined by a candidate's skills, expertise, or experience. In the United States, we have three geographic pay zones. For this role, our current base pay ranges for new hires in each zone are: Zone A: $140,100 - $186,800 Zone B: $126,100 - $168,200 Zone C: $116,300 - $155,100 This role may also be eligible for benefits, bonuses, commissions, and equity. Please visit go.atlassian.com/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter. Our Perks & Benefits Atlassian offers a variety of perks and benefits to support you, your family and to help you engage with your local community. Our offerings include health coverage, paid volunteer days, wellness resources, and so much more. Visit go.atlassian.com/perksandbenefits to learn more. About Atlassian At Atlassian, we're motivated by a common goal: to unleash the potential of every team. Our software products help teams all over the planet and our solutions are designed for all types of work. Team collaboration through our tools makes what may be impossible alone, possible together. We believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines. To provide you the best experience, we can support with accommodations or adjustments at any stage of the recruitment process. Simply inform our Recruitment team during your conversation with them. To learn more about our culture and hiring process, visit go.atlassian.com/crh ."
4172362992,Business Intelligence Data Engineer,TomoCredit,"Who We Are As seen on TechCrunch, Forbes, and Bloomberg, join one of fastest growing areas in FinTech by taking on the credit system. Work directly with one of Inc.’s top female founders and learn from some of the most talented people in the industry. Headquartered in San Francisco, Tomo’s mission is to replace the outdated credit system and open access to banking. We value passionate, down to earth, “can do” people who enjoy fine-tuning small details, without losing sight of the big picture. We are looking for someone who is driven to get things done and views obstacles as an exciting challenge that demands a creative solution. You are a self-starter with a high degree of rigor, organization, and discipline to get things done. Above all else, this role requires someone who takes great pride in their work and is inspired and motivated by their role in improving the way millions of people build their financial future. Job Summary: As a Business Intelligence Engineer / Analytics Engineer, you will be responsible for building and maintaining the data models, dashboards, and analytics pipelines that power our decision-making. You’ll collaborate with teams across product, engineering, operations, and finance to ensure we have reliable, scalable, and actionable data. Key Responsibilities: Data Infrastructure & Modeling: Design, build, and maintain scalable data models in our data warehouse (e.g., Snowflake, BigQuery, Redshift). BI & Reporting: Develop interactive dashboards and reports using tools like Looker, Tableau, or Power BI to provide key business insights. ETL & Data Pipelines: Create, optimize, and maintain ETL processes using dbt, Airflow, or similar tools. Data Quality & Governance: Ensure data accuracy, consistency, and integrity across all systems. Cross-Functional Collaboration: Work closely with product, engineering, finance, and other stakeholders to understand data needs and deliver insights. Advanced Analytics: Conduct deep-dive analyses to identify trends, opportunities, and areas for improvement. Automation & Optimization: Implement automation and performance improvements for reporting and analytics workflows. Qualifications: 3+ years of experience as a Business Intelligence Engineer, Analytics Engineer, or similar role. Hands-on experience with dbt (data modeling, transformations, testing). Strong SQL skills and experience with data modeling best practices. Experience with cloud data warehouses (e.g., Snowflake, BigQuery, Redshift). Proficiency with BI tools like Looker, Tableau, Power BI, or similar. Experience with ETL and orchestration tools like Airflow, Fivetran, or custom-built pipelines. Hands-on experience with Google Analytics, including data extraction, analysis, and reporting, to support cross-functional teams with actionable insights and data-driven decision-making. Understanding of data governance, security, and compliance best practices. Ability to communicate complex data concepts to non-technical stakeholders. Experience in fintech, credit, or financial services is a plus. Bonus: Familiarity with Python, R, or other data scripting languages. Why TomoCredit? Join a team where your work makes a significant impact on the future of credit and banking. At TomoCredit, you’ll collaborate with seasoned FinTech executives from Square, Lending Club, and American Express. We’re committed to fostering a culture where people love what they do and the team they work with. Here’s what we offer: Competitive Salary: Reflecting your skills and experience. Equity: We share our success with our employees through ownership stakes. Insurance: Comprehensive medical, dental, and vision benefits. Flexible Vacation Policy: We trust you to manage your time wisely to prevent burnout. Career Growth Opportunities: Take advantage of mentorship from seasoned professionals and expand your role as TomoCredit grows. Company-Sponsored Outings: Build meaningful relationships with your team outside of work. Commitment to Diversity At TomoCredit, diversity and inclusion are core to our values. We welcome applications from all qualified individuals, regardless of race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. Join us in reshaping the credit landscape and empowering millions to build a stronger financial future!"
4172879369,Data Engineer,Largeton Group,"Job Title: Senior Data Engineer Date: January 2025 Job Purpose: To work with Lead Data Engineers on building and maintaining data pipelines. Must be well-versed in data flow and support of analytical applications and have knowledge of modern programming languages, web technologies, backend infrastructure, databases, and AWS cloud services. Job Location: Hybrid, Nashville Department, Division: Technology, Global IT Reports to: VP, Data Warehouse & Analytics Manages Others: No Responsibilities: Collaborate with product manager, business analyst, and solutions architect Provide subject matter expertise Diagnose and remediate development issues Participate in code reviews Write efficient code Build reusable components and libraries Develop guidelines on code documentation Stay current with industry trends Promote teamwork Mentor junior members Requirements: 5 - 7+ years of Data Engineer experience Knowledge of modern database technologies and AWS Experience with unit and integration testing Strong documentation skills Knowledge of development life cycle phases and solution delivery for cloud-based systems Self-motivated and organized Ability to work across time zones (US and UK) Skills: AWS Serverless, Cloud Security, DevOps, Cloud Migration, Containers, Dockers Languages: SQL/NOSQL, Python, Node JS, Chart JS Knowledge of AWS Services like Event Bridge, Step Functions, Lambda, Glue, CloudWatch, CloudFront, DMS Knowledge of Python or PySpark, Liquibase, CI/CD Knowledge of Agile, SAFE, scrum, CI/CD, and DevOps Effective communication and interpersonal skills Nice to Haves: Knowledge of designing and building high volume serverless solutions in AWS Experience with Front End technologies like Angular/React JS Knowledge of ETL solutions such as Glue & Lambda functions Knowledge on dashboard platforms such as AWS QuickSight, Google Looker, Tableau, PowerBI Knowledge of big data technologies like AWS Redshift, Hive and Spark Experience with AWS Database Migration Service (DMS) Experience with CRM/Finance/Accounting systems AWS Certification."
4164193356,Data Engineer,Infosys,"Infosys is seeking a Senior Data Engineer. This position’s primary responsibility will be to provide technical expertise and coordinate for day-to-day deliverables for the team. The chosen candidate will assist in the technical design of large business systems; builds applications, interfaces between applications, understands data security, retention, and recovery. The role holder should be able to research on technologies independently to recommend appropriate solutions & should contribute to technology-specific best practices & standards; contribute to success criteria from design through deployment, including, reliability, cost-effectiveness, performance, data integrity, maintainability and scalability; contributes expertise on significant application components, program languages, databases, operating systems, etc., and guides/mentors the team during the build and test phases. Candidate must be located within commuting distance of Charlotte/Raleigh, NC or be willing to relocate to the area. This position may require travel to project locations. Required Qualifications Bachelor’s degree or foreign equivalent required from an accredited institution. Will also consider three years of progressive experience in the specialty in lieu of every year of education. At least 4 years of Information Technology experience. Experience in creating data engineering pipelines using Python with Object oriented concepts, Pyspark and AWS. Design, develop and implement new features to existing framework using PySpark and Python. Write efficient and effective standalone scripts in PySpark with transformations as per the defined business logic. Preferred Qualifications Work closely with the team to understand the requirements and develop solutions. Test and debug code to ensure it produces the desired results. Document all programming tasks and procedures for future reference and troubleshooting Use your expertise in Python and Object-oriented concepts to solve complex problems and implement robust solutions. Proficient in Python, PySpark, and Object-oriented programming concepts. Proven experience as a Senior Data Engineer or similar role. Strong problem-solving techniques with an ability to troubleshoot complex software issues. Experience with AWS is preferred, but not mandatory. Excellent communication skills, both written and verbal. Self-motivated and able to work independently with minimal supervision. Ability to work in team in diverse/ multiple stakeholder environment. Experience and desire to work in a Global delivery environment. Ability to learn and adapt to emerging technologies and enhance skills."
4157959045,Data Engineer Intermediate,TieTalent,"About It's fun to work in a company where people truly BELIEVE in what they are doing! Headquartered in Arvada, Colorado with operations and presence in Europe, the Middle East, India, Asia, Japan and China, Sundyne is a global manufacturer of precision-engineered, highly reliable, safe and efficient centrifugal pumps and compressors for use in chemical, petrochemical, hydrocarbon, hydrogen, pharmaceutical, power generation and industrial applications. Sundyne is a leader in delivering precision-engineered and highly reliable pumps & compressors to many of the world's most important markets, including energy, chemical, industrial, carbon capture, clean hydrogen, and renewable fuels. Sundyne pumps and compressors are available in API, ANSI/ASME, ISO and other industry compliant designs. To learn more about the Sundyne family of precision-engineered pumps and compressors, please visit www.sundyne.com. Position Description Sundyne is seeking an Intermediate Data Engineer on-site in our Arvada CO office, Remote or Remote Hybrid. Responsibilities will be to enhance our existing SSIS Data Analytics Cubes and DataSet solutions along with developing data mart and data warehouse and establish the roadmap for the next generation of Data/ML/AI tool sets. Support, Maintain and Enhance our Data warehouse solutions that provide our business leaders with the data and insights they need to make decisions and service our customers with excellence. Job Duties & Responsibilities The primary responsibility of the Data Engineer is to create and provide business value from corporate data assets by Building/supporting multi-dimensional & tabular data models using SSIS, SSRS and other Microsoft technologies to enhance our Data Warehouse Utilize SQL to curate and query large data sets, perform analyses, create custom views, and troubleshoot data anomaly issues back to the source systems. Maintain and enhance expertise across an application technology stack (Microsoft SQL) as well as a technology domain (BI/DW and Data Analytics) Design and map data models to shift raw data into meaningful insights and evaluate the effectiveness and capability of new data sources and data gathering techniques. Ability to embrace and leverage new technologies while working effectively with other information technology professionals and business users to ensure that the data solutions and platforms are stable, affective, efficient and provide value to business needs. Assist in leading the data management and governance processes with the strategic and operational definition, design, implementation, and continuous innovation. Also ensure Data Security, Privacy, Protection, Integrity, and Sensitivity Perform tests and validate all data flows and prepare all ETL processes according to business requirements and incorporate all business requirements into all design specifications. Documents all technical and system specifications documents for all ETL processes and perform unit tests on all processes and prepare required programs and scripts. Develop strong data documentation about algorithms, parameters, models, data flows, and Transformation. Ensure accuracy of data thru testing and Business QA processes Skills & Abilities Degree in data engineering, Computer Science, Statistics, or related fields within advanced data and analytics 6 + years Data Engineer using MS SQL Server, TSQL and SSIS Must understand Relational and Dimensional database modeling. Must exhibit a deep understanding and knowledge of the Microsoft BI Stack, including: SSIS, SSRS, SSAS, SharePoint, PowerPivot, Power Query, MDX, DAX, and PowerBI Advanced experience using MS SQL to extract data, understand data structures, run queries, and analyze data in a data warehouse environment Strong understanding of tier one Manufacturing ERP System data (JDE, SAP, Syteline, Navision) Must have proven experience in ETL and experience in Tools to support Data Migration from one or more Source(s) to Destination with application of transformation rules. Effective Communication skills, both written and verbal Highly proficient with Microsoft Office Suite: Excel (advanced features), Word, Outlook, Power Point, Teams, Share Point Strong communication skills and the ability to synthesize findings from analyses into clear, concise communications for business leadership Team player attitude and strong ability to collaborate with colleagues across the globe Additional Skill Sets A Plus Microsoft Dynamics CRM System data RDBMS skills with dimensional modelling (SSMS) Azure Data lakes and AI/ML feature sets. Azure Databricks, Azure Data Factory, Azure Synapse, Fabric Python, Power Shell If you like growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us! Compensation Details Annual Salary: $120,000.00 - $125,000.00 Additional Compensation The Salary offered will be determined based on the applicant's education, experience, skills, knowledge, abilities, and will be compared with internal equity along with market data for this position. This position may be eligible to participate in the Company's Sales Incentive Plan with a target of up to 30% of base salary, subject to the terms and conditions of the plan. Payment is based on individual performance against established sales targets. This position may also be eligible to receive a Relocation bonus, payable as a taxable lump sum, in accordance with the Sundyne Relocation Policy. Application Deadline: 2025-04-09 Nice-to-have skills SSIS SQL ETL SAP Azure Data Factory Python Colorado, United States Work experience Data Engineer Data Infrastructure Languages English"
4171303033,Data Engineer Intern,The Clorox Company,"Clorox is the place that’s committed to growth – for our people and our brands. Guided by our purpose and values, and with people at the center of everything we do, we believe every one of us can make a positive impact on consumers, communities, and teammates. Join our team. #CloroxIsThePlace Your role at Clorox: Join our dynamic team as a Data Engineer Intern! As a Data Engineer Intern at our organization, you will have the opportunity to work with cutting-edge technologies within the Azure stack. You’ll collaborate closely with the Finance Transformation Team, gain hands-on experience, and contribute to impactful data engineering projects. If you have a passion for data, analytics, and cloud technologies and are eager to develop your business data acumen, this role is perfect for you! In this role, you will: Key Responsibilities Quality Assurance (QA) Tasks: Assist in identifying and resolving QA bugs related to data pipelines and processes, ensuring data integrity and reliability. Validate data accuracy, completeness, and consistency by performing rigorous testing and analysis. Pipeline Engineering: Participate in designing, building, and maintaining data pipelines. Implement data transformations, data cleansing, and ETL processes to ensure high-quality data flow. Collaborate with senior engineers to enhance pipeline efficiency and performance. Small Feature Development: Take ownership of small features within the data pipeline. Write code to handle data ingestion, processing, and storage, ensuring seamless data integration. Independent Project: Lead a small independent project related to data engineering, choosing a topic of interest (e.g., optimizing pipeline performance, automating data validation). Present your findings and recommendations to the team. What we look for: Key Skills, Abilities, And Experience Required Education: Currently a Junior or Rising Senior in college pursuing a STEM degree (e.g., Computer Science, Engineering, Information Technology, etc.). Technical Skills: Proficiency in SQL, Python, and PySpark. Familiarity with Azure services such as Data Factory, Synapse, Databricks, and Azure Functions. Experience with data integration using APIs. Knowledge of data visualization tools (Power BI, Tableau). Analytical Skills: Strong problem-solving abilities with the capability to provide solutions and recommendations. Ability to document business requirements effectively in the form of Standard Operating Procedures (SOPs). Collaboration and Communication: Excellent teamwork and communication skills with cross-functional partners. Workplace type: We seek out and celebrate diverse backgrounds and experiences. We’re looking for fresh perspectives, a desire to bring your best, and a non-stop drive to keep growing and learning. At Clorox, we have a Culture of Inclusion. We believe our values-based culture connects to our purpose and helps our people be the best versions of themselves, professionally and personally. This means building a workplace where every person can feel respected, valued, and fully able to participate in our Clorox community. Learn more about our I&D program & initiatives here . Benefits we offer to help you be well and thrive: Competitive compensation Generous 401(k) program in the US and similar programs in international Health benefits and programs that support both your physical and mental well-being Flexible work environment, depending on your role Meaningful opportunities to keep learning and growing Half-day Fridays, depending on your location Please apply directly to our job postings and do not submit your resume to any person via text message. Clorox does not conduct text-based interviews and encourages you to be cautious of anyone posing as a Clorox recruiter via unsolicited texts during these uncertain times. To all recruitment agencies: Clorox (and its brand families) does not accept agency resumes. Please do not forward resumes to Clorox employees, including any members of our leadership team. Clorox is not responsible for any fees related to unsolicited resumes."
4164169385,Data Engineer,WHOOP,"At WHOOP, we're on a mission to unlock human performance. WHOOP empowers members to perform at a higher level through a deeper understanding of their bodies and daily lives. WHOOP is seeking a dynamic Data Engineer who thrives on innovation and is ready to revolutionize our data operations. In this role, you'll design, build, and optimize scalable data pipelines and platforms that serve as the backbone of our data-driven insights. With a strong focus on crafting robust ETL/ELT processes and managing cutting-edge AWS infrastructure, you'll integrate modern data tools—including Snowflake, DBT, Kafka, and Spark—to elevate our analytical capabilities. If you're excited about harnessing AI to supercharge efficiency and drive breakthrough innovations, we want you to join our forward-thinking team and make a tangible impact on the future of our data ecosystem. Responsibilities Write and maintain high-quality, reusable code in Python and Pyspark to develop and maintain ELTs and data pipelines. Utilize Kafka and Spark for real-time streaming and batch data processing. Implement and optimize data warehousing solutions using Snowflake. Create and manage transformation models with DBT to ensure consistent data quality and agile analytics. Architect and manage AWS infrastructure (e.g., EC2, S3, Lambda, RDS) to support scalable and secure data processing. Leverage AI tools to automate tasks, optimize workflows, and drive overall efficiency. Collaborate with cross-functional teams (data scientists, analysts, etc.) to understand and meet evolving data needs. Document processes and continuously seek improvements in the data platform. Qualifications Bachelor’s degree in Computer Science, Engineering, or a related field; or equivalent practical experience. Experience designing and implementing ETL/ELT processes. Solid understanding of SQL and modern data warehousing concepts. Familiarity with AI tools like Copilot / ChatGPT and their use on driving efficiency in the software development life cycle. Proficiency using DBT for data modeling and transformation is a plus. Hands-on experience with Kafka and Spark for data processing is a plus. Knowledge of containerization, orchestration (e.g., Docker, Kubernetes), and infrastructure-as-code is a plus. Excellent problem-solving skills, strong communication abilities, and the capacity to work collaboratively in an agile environment. This role is based in the WHOOP office located in Boston, MA. The successful candidate must be prepared to relocate if necessary to work out of the Boston, MA office. Interested in the role, but don’t meet every qualification? We encourage you to still apply! At WHOOP, we believe there is much more to a candidate than what is written on paper, and we value character as much as experience. As we continue to build a diverse and inclusive environment, we encourage anyone who is interested in this role to apply. WHOOP is an Equal Opportunity Employer and participates in E-verify to determine employment eligibility. It is unlawful in Massachusetts to require or administer a lie detector test as a condition of employment or continued employment. An employer who violates this law shall be subject to criminal penalties and civil liability."
4154582788,Data Engineer,FanDuel,"About Fanduel FanDuel Group is the premier mobile gaming company in the United States. FanDuel Group consists of a portfolio of leading brands across mobile wagering including, America’s #1 Sportsbook FanDuel Sportsbook, its leading iGaming platform FanDuel Casino, the industry’s unquestioned leader in horse racing and advance-deposit wagering, FanDuel Racing and its daily fantasy sports product. In addition, FanDuel Group operates FanDuel TV, its broadly distributed linear cable television network and FanDuel TV+, its leading direct-to-consumer OTT platform. FanDuel Group has a presence across all 50 states and Puerto Rico with approximately 17 million customers and 31 retail locations. The company is based in New York with offices in Los Angeles, Atlanta and Jersey City, as well as in Canada, Scotland, Ireland, Portugal, Romania and Australia. FanDuel Group is a subsidiary of Flutter Entertainment, the world's largest sports betting and gaming operator with a portfolio of globally recognized brands and traded on the New York Stock Exchange (NYSE: FLUT). THE ROSTER At FanDuel, we give fans a new and innovative way to interact with their favorite games, sports and teams. We’re dedicated to building a winning team and we pride ourselves on being able to make every moment mean more, especially when it comes to your career. So, what does “winning” look like at FanDuel? It’s recognition for your hard-earned results, a culture that brings out your best work—and a roster full of talented coworkers. Make no mistake, we are here to win, but we believe in winning right. That means we’ll never compromise when it comes to looking out for our teammates. From creatives professionals to cutting edge technology innovators, FanDuel offers a wide range of career opportunities, best in class benefits, and the tools to explore and grow into your best selves. At FanDuel, our principle of “We Are One Team” runs through all our offices across the globe, and you can expect to be a part of an exciting company with many opportunities to grow and be successful. THE POSITION Our roster has an opening with your name on it FanDuel is looking for an experienced Data Engineer with a deep understanding of large-scale data handling and processing best practices in a cloud environment to help us build scalable systems. As our data is a key component of the business used by almost every facet of the company, including product development, marketing, operations, and finance. It is vital that we deliver robust solutions that ensure reliable access to data with a focus on quality and availability. Our competitive edge comes from making decisions based on accurate and timely data and your work will provide access to that data across the whole company. Looking ahead to the next phase of our data platform we are keen to do more with real time data processing and working with our data scientists to create machine learning pipelines We're seeking dynamic professionals to join our business-critical Risk and Trading data team at FanDuel, where you'll harness cutting-edge technologies to support risk analysis, pricing models, and trading operations. Collaborate with a broad array of Risk, Trading and Fraud stakeholders and deploy crucial data assets to advance operational and machine learning use cases. THE GAME PLAN Everyone on our team has a part to play Creating and maintain optimal data pipelines Implementing data pipelines required in the data warehouse and data lake in batch or real-time using data transformation technologies. Identifying and implementing internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability Deploying data models and views with large datasets that meet functional / non-functional business requirements Delivering data integration solutions to downstream marketing and campaign software Delivering quality production-ready code in an agile environment Delivering test plans, monitoring, debugging and technical documents as a part of development cycle Creating data tools for analytics and working with stakeholders across all departments to assist with data-related technical issues and supporting their data infrastructure needs Adhere to engineering and operational excellence THE STATS What we're looking for in our next teammate 2-4+ years of experience writing Python, SQL and DBT Proficiency in relational databases and data warehouses (Delta Lake knowledge is a plus) Show proficiency understanding complex ETL processes Understanding of Risk and/or Fraud terminology Knowledge of data integrity and relational rules Understanding of AWS Ability to quickly learn new technologies is critical Proficiency with agile or lean development practices Player Benefits We treat our team right From our many opportunities for professional development to our generous insurance and paid leave policies, we’re committed to making sure our employees get as much out of FanDuel as we ask them to give. Competitive compensation is just the beginning. As part of our team, you can expect: An exciting and fun environment committed to driving real growth Opportunities to build really cool products that fans love Career and professional development resources to help you refine your game plan for owning and driving your career and development Be well, save well and live well - with FanDuel Total Rewards your benefits are one highlight reel after another FanDuel is an equal opportunities employer and we believe, as one of our principal states, “We Are One Team!” We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, Veteran status, or another other characteristic protected by state, local or federal law. We believe FanDuel is strongest and best able to compete if all employees feel valued, respected, and included. We want our team to include diverse individuals because diversity of thought, diversity of perspectives, and diversity of experiences leads to better performance. Having a diverse and inclusive workforce is a core value that we believe makes FanDuel stronger and more competitive as One Team! The applicable salary range for this position is $108,000 - $142,000, which is dependent on a variety of factors including relevant experience, location, business needs and market demand. This role may offer the following benefits: medical, vision, and dental insurance; life insurance; disability insurance; a 401(k) matching program; among other employee benefits. This role may also be eligible for short-term or long-term incentive compensation, including, but not limited to, cash bonuses and stock program participation. This role includes paid personal time off and 14 paid company holidays. FanDuel offers paid sick time in accordance with all applicable state and federal laws."
4132851002,Data Engineer,Paradigm,"At Paradigm, we are changing the future of finance! By joining us at this early stage, you’ll be building cutting-edge, distributed financial service infrastructure that will reshape financial services across CeFi and DeFi markets. About Paradigm Paradigm is a zero-fee, institutional liquidity network for derivatives traders across CeFi and DeFi. We provide unified access to multi-asset, multi-protocol liquidity on demand without compromising on execution preferences, costs, and immediacy. We’ve built the largest network of institutional counterparties in crypto, with over 1000 institutional clients trading over $10 B per month. We are a diverse, global team led by our organizational principles and united by our mission to bring on-demand liquidity for traders, anytime and anywhere, without compromises. We also strive to ship faster than anyone else in the industry! We are backed by the best traders and investors in the space, including Jump Capital, Genesis Trading, Dragonfly Capital, QCP Capital, Optiver US, IMC, GSR Markets, Akuna Capital, Fidelity Digital Assets CMT Digital, Goldentree Asset Management, Amber Group, OK Group, Bybit Fintech, and CoinShares. Your Mission As a vital member of our data engineering team, you’ll architect and implement robust data infrastructure that transforms raw data into actionable insights. You’ll work on building scalable pipelines and data models that power critical decision-making across the organization. Your expertise will be crucial in establishing data best practices and ensuring data quality, accessibility, and reliability throughout our systems. What You’ll Do Design & Build: Create and maintain scalable data pipelines, ETL processes, and data warehousing solutions that handle complex data requirements. Optimize & Scale: Improve data infrastructure performance, implement data quality measures, and develop automated monitoring systems. Empower & Enable: Partner with product, engineering and go-to-market teams to deliver data solutions that drive strategic insights. Rapid Response: Quickly address time-sensitive data needs and ad-hoc requests from stakeholders, turning around critical analyses and data solutions with urgency while maintaining accuracy. What You’ll Bring Expertise: 7+ years of data engineering experience Data Architecture: Deep knowledge of data modeling, warehouse design, and ETL best practices. Technical Mastery: Proficiency with modern data stack (Snowflake, Airflow/DBT) and AWS. Systems Thinking: Experience with distributed systems, data streaming (Kafka/Kinesis), and optimization of large-scale data workflows. Agility: Proven track record of efficiently tackling urgent data requests and providing quick solutions to business-critical data needs. salary range: USD 142,000 to 237,000 At Paradigm we're doing something different. Moving forward we ask all candidates to send in a video with their application, telling us why they want to be part of the team. The video should be no longer than 1 minute and via a link to a streaming platform of your choice. (No files or download links will be accepted) Your Perks & Benefits Competitive Pay: Top-tier compensation in the industry. Generous PTO: Unlimited vacation. Full Benefits: Comprehensive packages tailored by country. Technology & Learning Allowances: 3,500 USD for your first-year setup, $2,000 USD refresh every 2 years, plus $1,000 USD annually for learning and development. Paradigm is an equal opportunity employer."
4138463912,Data Engineer,Suno,"About Suno At Suno, we are building a future where anyone can make music. You can make a song for any moment with just a few short words. Award-winning artists use Suno, but our core user base consists of everyday people making music — often for the first time. We are a team of musicians and AI experts, including alumni from Spotify, TikTok, Meta and Kensho. We like to ship code, make music and drink coffee. Our company culture celebrates music and experimenting with sound — from lunchroom conversations to the studio in our office. About The Role We’re seeking talented data engineers to join our founding team, working closely with key stakeholders and taking ownership of building and shaping Suno’s core data foundation. Check out our Suno version of the job here! What You’ll Do Serve as a critical contributor to the Suno products team, providing insights and solutions that influence high-level decisions and shape the product roadmap. Design, develop, and maintain complex data products, systems, platforms, and pipelines to build scalable, secure, and high-quality big data solutions that seamlessly integrate diverse data sources, process high-volume real-time and batch data, and ensure data integrity, quality, and compliance. Collaborate with scientists, ML engineers, software developers, business leaders, and product teams to define data requirements, architect solutions, and implement data-driven opportunities that enhance customer experiences. Leverage advanced analytics and data engineering practices to uncover actionable customer insights that drive the development of innovative and enhanced customer experiences for Suno. Implement and monitor data systems to ensure high availability, reliability, and scalability while advocating for and applying best practices in big data engineering and analytics. What You’ll Need 5+ years of experience in data engineering, with a strong grasp of Big Data engineering concepts, data architecture design, and performance optimization. Experience with data modeling, warehousing and building ETL pipelines. Experience with SQL and Python. Experience in scaling data pipelines from the ground up (0 to 1) Familiarity with Airflow, DBT, and Snowflake is a strong advantage. Passionate about engineering excellence, rapid iteration, learning, and hard work. Technical leadership or management experience is a plus. A love of music (listening, exploring, making) is a huge plus. Additional Notes: Applicants must be eligible to work in the US. Compensation The annual salary/OTE range for the target level for this role is $170,000 - $240,000 + target equity + benefits (including medical, dental, vision, and 401k) Benefits Healthcare for you and your dependents, with vision and dental 401k with match Generous commuter benefit Flexible PTO"
4113934016,Data Engineer,PayPal,"The Company PayPal has been revolutionizing commerce globally for more than 25 years. Creating innovative experiences that make moving money, selling, and shopping simple, personalized, and secure, PayPal empowers consumers and businesses in approximately 200 markets to join and thrive in the global economy. We operate a global, two-sided network at scale that connects hundreds of millions of merchants and consumers. We help merchants and consumers connect, transact, and complete payments, whether they are online or in person. PayPal is more than a connection to third-party payment networks. We provide proprietary payment solutions accepted by merchants that enable the completion of payments on our platform on behalf of our customers. We offer our customers the flexibility to use their accounts to purchase and receive payments for goods and services, as well as the ability to transfer and withdraw funds. We enable consumers to exchange funds more safely with merchants using a variety of funding sources, which may include a bank account, a PayPal or Venmo account balance, PayPal and Venmo branded credit products, a credit card, a debit card, certain cryptocurrencies, or other stored value products such as gift cards, and eligible credit card rewards. Our PayPal, Venmo, and Xoom products also make it safer and simpler for friends and family to transfer funds to each other. We offer merchants an end-to-end payments solution that provides authorization and settlement capabilities, as well as instant access to funds and payouts. We also help merchants connect with their customers, process exchanges and returns, and manage risk. We enable consumers to engage in cross-border shopping and merchants to extend their global reach while reducing the complexity and friction involved in enabling cross-border trade. Our beliefs are the foundation for how we conduct business every day. We live each day guided by our core values of Inclusion, Innovation, Collaboration, and Wellness. Together, our values ensure that we work together as one global team with our customers at the center of everything we do – and they push us to ensure we take care of ourselves, each other, and our communities. Job Description Summary: As a Data Engineer on the Credit Platform Data team at PayPal, you'll play a key role in building and enhancing tools for data processing, enabling our internal business units to leverage data efficiently. You'll develop secure, high-performing data integration and ETL processes, participating in all stages of development from, analysis to production releases. Your responsibilities will include delivering new features, ensuring quality, and collaborating closely with the Product team in an agile environment. Job Description: As a Data Engineer on the Credit Platform Data team at PayPal, you'll play a key role in building and enhancing tools for data processing, enabling our internal business units to leverage data efficiently. You'll develop secure, high-performing data integration and ETL processes, participating in all stages of development from analysis to production releases. Your responsibilities will include delivering new features, ensuring quality, and collaborating closely with the Product team in an agile environment. Responsibilities: Design, build, and maintain robust data pipelines and ETL processes to ingest, transform, and load data from various sources into our data warehouse, ensuring scalability and efficiency. Collaborate with product managers, analysts, and other stakeholders to understand data requirements and develop solutions that meet business needs while accommodating large volumes of data. Ensure the reliability, availability, and scalability of our data systems, monitoring performance and optimizing as needed to handle increasing data volumes. Implement automated data quality checks and validation processes to ensure data integrity and accuracy at scale. Troubleshoot data-related issues, identify root causes, and implement solutions in a timely manner to minimize impact on data processing. Create and maintain design documents and documentation for data pipelines, systems, and processes. Participate actively in design and code reviews. Stay current with emerging technologies and trends in data engineering, recommending and implementing improvements as necessary to support scalability and growth. Qualifications: Bachelor's degree in Computer Science, Engineering, or a related field. 3+ years of proven experience as a Data Engineer or similar role, with a strong background in database development, ETL processes, and software development. Proficiency in SQL and scripting languages such as Python, with experience working with relational databases. Proficiency in PySpark, Pandas or other data processing libraries. Familiarity with data warehousing concepts and tools, such as AWS Redshift, Google BigQuery, or Snowflake, and experience optimizing performance for large-scale data processing. Experience with data modeling, schema design, and optimization techniques for scalability. Strong analytical and problem-solving skills, with the ability to troubleshoot complex data issues and optimize data processing pipelines for scale. Experience with AWS or GCP as well as experience with Unix/Linux operating systems and shell scripting. Excellent communication and collaboration skills, with the ability to work effectively in a team environment. Self-motivated and proactive, with a passion for continuous learning and professional development. For the majority of employees, PayPal's balanced hybrid work model offers 3 days in the office for effective in-person collaboration and 2 days at your choice of either the PayPal office or your home workspace, ensuring that you equally have the benefits and conveniences of both locations. Our Benefits: At PayPal, we’re committed to building an equitable and inclusive global economy. And we can’t do this without our most important asset—you. That’s why we offer benefits to help you thrive in every stage of life. We champion your financial, physical, and mental health by offering valuable benefits and resources to help you care for the whole you. We have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https://www.paypalbenefits.com Who We Are: To learn more about our culture and community visit https://about.pypl.com/who-we-are/default.aspx Commitment to Diversity and Inclusion PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state, or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at paypalglobaltalentacquisition@paypal.com. Belonging at PayPal: Our employees are central to advancing our mission, and we strive to create an environment where everyone can do their best work with a sense of purpose and belonging. Belonging at PayPal means creating a workplace with a sense of acceptance and security where all employees feel included and valued. We are proud to have a diverse workforce reflective of the merchants, consumers, and communities that we serve, and we continue to take tangible actions to cultivate inclusivity and belonging at PayPal. Any general requests for consideration of your skills, please Join our Talent Community. We know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don’t hesitate to apply. REQ ID R0121691"
4138522109,Data Engineer,Landbase,"Landbase leverages the experience of 100+ world class sales professionals and AI to deliver targeted, high-quality leads on autopilot. Our mission is to achieve GTM automation so humans no longer need to work for their software so they can reclaim their day. We're building GTM-1 Omni - the world's first action model purpose built for lead generation. About The Role We're seeking a Data Engineer to design and implement scalable data pipelines that power our AI models and analytics. Required Skills & Experience Design and implement ETL pipelines in PySpark and/or Scala Spark Orchestrate complex data workflows in Airflow Advanced SQL skills and experience with BigQuery Hands-on experience with MongoDB, Elasticsearch, and PostgreSQL Proficiency with GCP Dataproc and cluster optimization Experience handling TB-scale unstructured data Optimize database performance and storage strategies Create and maintain data quality monitoring systems Collaborate with ML Engineers on production model deployment Stay current with emerging AI tools and technologies 3+ years of experience in large scale data engineering Nice-to-Have Qualifications Experience with PyTorch, Hugging Face, or other ML frameworks Background in LLM operations and deployment Familiarity with Ray for distributed computing Experience with real-time data streaming architectures Background in sales/marketing data systems Previous experience in startup or AI-driven environments Benefits & Perks Competitive compensation Comprehensive health benefits Flexible work arrangements Professional development opportunities Exciting work with cutting-edge AI technology Collaborative and innovative work environment Regular team events and gatherings"
